{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import  regularizers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnsvm():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(64,kernel_size=(4,4),activation=\"relu\",input_shape=(200,150,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,4)))\n",
    "    model.add(Conv2D(64,kernel_size=(3,5),activation=\"relu\",kernel_regularizer=regularizers.l2(0.04)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64,kernel_size=(3,5),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation=\"relu\",kernel_regularizer=regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64,activation=\"relu\",kernel_regularizer=regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32,activation=\"relu\"))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(2,activation=\"softmax\"))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=optimizers.Adam(lr=0.0001,beta_1=0.9,beta_2=0.9,epsilon=1e-8,decay=0.0),metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 197, 147, 64)      3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 197, 147, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 98, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 96, 32, 64)        61504     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 48, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 46, 12, 64)        61504     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1130624   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 1,267,426\n",
      "Trainable params: 1,267,298\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=cnnsvm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagenerator=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_generator=datagenerator.flow_from_directory('dataset/train',\n",
    "    target_size=(200,150),\n",
    "    batch_size=10,\n",
    "    class_mode='categorical')\n",
    "    \n",
    "    \n",
    "test_generator=datagenerator.flow_from_directory('dataset/test',\n",
    "    target_size=(200,150),\n",
    "    batch_size=2,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.1553 - acc: 1.0000 - val_loss: 3.1272 - val_acc: 1.0000\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.2710 - acc: 0.9312 - val_loss: 3.0873 - val_acc: 1.0000\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.0810 - acc: 1.0000 - val_loss: 3.0668 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.1890 - acc: 0.9153 - val_loss: 3.0431 - val_acc: 1.0000\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.0393 - acc: 1.0000 - val_loss: 3.0263 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.1047 - acc: 0.9757 - val_loss: 3.0055 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.9975 - acc: 1.0000 - val_loss: 2.9839 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.0038 - acc: 1.0000 - val_loss: 2.9615 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.9574 - acc: 1.0000 - val_loss: 2.9368 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 3.0072 - acc: 0.9800 - val_loss: 2.9100 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.9149 - acc: 1.0000 - val_loss: 2.8836 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.8757 - acc: 1.0000 - val_loss: 2.8588 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.8519 - acc: 1.0000 - val_loss: 2.8266 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.8174 - acc: 1.0000 - val_loss: 2.7923 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.8255 - acc: 0.9799 - val_loss: 2.7646 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.8278 - acc: 0.9600 - val_loss: 2.7419 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.7403 - acc: 1.0000 - val_loss: 2.7279 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.7501 - acc: 0.9799 - val_loss: 2.6972 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.6918 - acc: 1.0000 - val_loss: 2.6745 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.6770 - acc: 1.0000 - val_loss: 2.6528 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.6988 - acc: 0.9600 - val_loss: 2.6253 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.6242 - acc: 1.0000 - val_loss: 2.6070 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.7577 - acc: 0.9200 - val_loss: 2.5837 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.5810 - acc: 1.0000 - val_loss: 2.6229 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.9824 - acc: 0.8800 - val_loss: 2.5592 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.5587 - acc: 1.0000 - val_loss: 2.5455 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.5477 - acc: 1.0000 - val_loss: 2.5461 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.6367 - acc: 0.9600 - val_loss: 2.5296 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.6007 - acc: 0.9396 - val_loss: 2.5062 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.5029 - acc: 1.0000 - val_loss: 2.5033 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "fit_history=model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=5,\n",
    "        epochs=30,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "model=load_model('model.hdf5')\n",
    "datagenerator=ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator=datagenerator.flow_from_directory('test',\n",
    "    target_size=(200,150),\n",
    "    batch_size=1,\n",
    "    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step\n",
      "[[0.3299407 0.6700593]]\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict_generator(test_generator,steps=len(test_generator),verbose=1)\n",
    "print(pred)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "label=['negative','positive']\n",
    "out=label[predicted_class_indices[0]]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todays date: 13/06/2022\n",
      "Today's malaria cases: 2\n"
     ]
    }
   ],
   "source": [
    "file= open('out.txt','w')\n",
    "file.write(out)\n",
    "file.close()\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "curr_date = today.strftime(\"%d/%m/%Y\")\n",
    "print(\"Todays date:\",curr_date)\n",
    "\n",
    "file=open(\"date.txt\",\"r\")\n",
    "t_date=file.read()\n",
    "file.close()\n",
    "\n",
    "file=open(\"daily_update.txt\",\"r\")\n",
    "mal_count=int(file.read())\n",
    "file.close()\n",
    "if curr_date==t_date:\n",
    "\tif out=='positive':\n",
    "\t\tmal_count+=1\n",
    "else:\n",
    "\tfile=open(\"date.txt\",\"w\")\n",
    "\tfile.write(curr_date)\n",
    "\tfile.close()\n",
    "\tif out=='positive':\n",
    "\t\tmal_count=1\n",
    "\telse:\n",
    "\t\tmal_count=0\n",
    "\t\t\n",
    "file=open(\"daily_update.txt\",\"w\")\n",
    "file.write(str(mal_count))\n",
    "file.close()\n",
    "\n",
    "print(\"Today's malaria cases:\",mal_count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
